# -*- coding:utf-8 -*-

# Some utils funciton for strings.

import re
import nltk

dataset_utils_string_english_vocab = set([w.lower() for w in nltk.corpus.words.words()])

def multi_spaces_to_one(s):
  s = re.sub(r'\s\s+', ' ', s)
  return s

def regular_process(s, minimum_length=1,
                    remove_strings=None,
                    replace_maps=None):
  """Some regular processes for a string.
  
  Parameters
  ----------
  s : str
    The input.
  minimum_length : int
    Minimum length of the input, if input has less characters,
    return empty string.
  remove_strings : list of str

  replace_maps : dict

  """
  if remove_strings is not None:
    if not isinstance(remove_strings, list):
      remove_strings = [remove_strings]
    for p in remove_strings:
      s = re.sub(p, '', s)
  if replace_maps is not None:
    for k, v in replace_maps.items():
      s = re.sub(k, v, s)
  if len(s) < minimum_length:
    s = ''
  return s

def encode_decode_rm_specified_code(text):
  """
  1. Encode to get bytes
  2. Check ascii
  3. rm some
  4. decode
  """
  byte_rep = text.encode()
  byte_rmed_list = []
  for b in byte_rep:
    if b == 239:
      byte_rmed_list.append(102)
    elif b == 172:
      byte_rmed_list.append(105)
    elif b == 129:
      pass
    elif b >=0 and b <= 126:
      byte_rmed_list.append(b)
    else:
      byte_rmed_list.append(32)
  byte_rep = bytes(byte_rmed_list)
  text = byte_rep.decode('utf-8')
  return text

def connect_some_f_pattern(text, infix='fi'):
  """HTML generated by `pdf2html` will fail at some *ff*, *fi* words.
  
  e.g.
  ' ef icient ' -> ' efficient ' if infix='fi'
  ' nd ' -> ' find ' if infix='fi'
  """
  # TODO(zcq) May be very slow
  spe_wrods = [w for w in english_vocab if infix in w]
  for w in spe_wrods:
    idx = w.find(infix)
    pre = w[:idx]
    suf = w[idx + len(infix):]
    text = re.sub(r'\s+%s\s{1,5}%s\s+' % (pre, suf), ' %sfi%s ' % (pre, suf), text)
  return text


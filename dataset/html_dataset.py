# This dataset parse html file generated by *pdf2htmlEX* command
# https://github.com/coolwanglu/pdf2htmlEX

from bs4 import BeautifulSoup
import os
import re

from lingua.dataset.dataset import BaseDataset
from lingua.dataset.utils_string import multi_spaces_to_one, \
    connect_some_f_pattern


def _special_code_transformer(s):
  map_dict = {
    '\ue263' : 'ffi',
    '\ue265' : 'fi',
    '\ue258' : 'ffi',
    '\ue262' : 'ff',
    '\ue077' : 'fi'
  }
  for k, v in map_dict.items():
    if k in s:
      s = s.replace(k, v)
  return s

class HTMLDataset(BaseDataset):
  """HTML to text."""
  def __init__(self, html_file_path,
               minimum_length=10,
               minimum_words=5):
    """Given a html, parse the text.

    html_file_path : str
      Path.
    minimum_length : int
      Minimum length of a paragraph.
    minimum_words : int
      Number of minimum words in a paragraph.
    """
    if not os.path.isfile(html_file_path):
      raise ValueError('%s not exist' % html_file_path)
    self._html_file_path = html_file_path
    self._minimum_length = minimum_length
    self._minimum_words = minimum_words

  def save_to(self, output_path):
    with open(output_path, 'w', encoding='utf-8') as f:
      for t in self.get_text():
        if len(t) > 0:
          f.write(t + '\n')

  def get_text(self):
    with open(self._html_file_path, 'r') as f:
      self._html_text = f.read()
    self._bs = BeautifulSoup(self._html_text)
    divs = self._bs.find_all('div')
    text_list = []
    text_para = ''
    for div in divs:
      for cont in div.contents:
        if cont.string is not None:
          temp_div_string = str(cont.string)
          text_para += _special_code_transformer(temp_div_string)
      if text_para.endswith('.'):
        text_list.append(text_para)
        text_para = ''
      elif len(text_para):
        text_para += ' '

    if len(text_para):
      text_list.append(text_para)
    return self.filter_text_list(text_list)

  def filter_text_list(self, text_list):
    """Filter text with some naive methods.
    """
    for text in text_list:
      text = multi_spaces_to_one(text.strip())
      text = connect_some_f_pattern(text)
      if not len(text.split()) > self._minimum_words:
        continue
      if not len(text) > self._minimum_length:
        continue
      yield text
